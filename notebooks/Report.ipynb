{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bfd474a-f790-40a4-ae31-eeba98865ab2",
   "metadata": {},
   "source": [
    "# Brief\n",
    "\n",
    "Steps taken to solve this case study are that of any end to end data science pipeline. Multiple insights about data were found during EDA. Next steps followed deciding on model , designing features for the same and training evaluation of model.\n",
    "\n",
    "# Steps\n",
    "\n",
    "## EDA\n",
    "\n",
    "1. Imbalance in class labels\n",
    "1. Long tailed distributions in multiple features were observed\n",
    "1. Interesting contour plots were seen with Weather variables and class labels\n",
    "\n",
    "## Model selection and feature selection\n",
    "\n",
    "1. Most of the features were hierachical in natue or categorical in nature\n",
    "1. This type of data is well modelled by decision trees\n",
    "1. Decision trees are light weight in nature and interpretable \n",
    "1. Hence used decision trees for modelling\n",
    "\n",
    "## Feature engineering and transformations\n",
    "\n",
    "1. Cleaning various columns such as `Wind_Direction` was done\n",
    "1. Cleaning text data `Description` was done using various regex filters\n",
    "1. In order for featurize `Description`\n",
    "    1. Keywords were found using keyword extractor\n",
    "    1. topk keywords were chosen to generate a binary vector\n",
    "    1. occurence of keyword in the description would make the binary vector of respective dimension as 1\n",
    "1. Featurizing `Zipcode`\n",
    "    1. As zip codes are hierarchical in nature\n",
    "    1. Each part of zip code marks a region\n",
    "    1. Zip code was split into 2 parts\n",
    "    1. first 2 digits of zip code named as to `zip_02` to create a new feature\n",
    "    1. next 3 digits of zip code named as `zip_25` to create a new feature\n",
    "    1. number of digits in zip code could be one feature that was added\n",
    "    1. is the zip code compound zip code like `1234-567` a boolean feature was added\n",
    "    \n",
    "\n",
    "1. As most of the variables were categorical in nature , category encoded them using \n",
    "    1. baseN encoder\n",
    "    1. binary encoder\n",
    "    1. ordinal encoder\n",
    "\n",
    "complete set of encoding methods applied is as follows:\n",
    "\n",
    "```python\n",
    "    categorical_features = {\n",
    "    \"Source\": \"base_2\",  # 3 unique values\n",
    "    \"Side\": \"base_2\",  # 2 unique values\n",
    "    \"City\": \"base_4\",  # 11895 unique values\n",
    "    \"County\": \"base_4\",  # 1713 unique values\n",
    "    \"State\": \"base_2\",  # 49 unique values\n",
    "    \"Timezone\": \"base_2\",  # 4 unique values\n",
    "    \"Airport_Code\": \"base_4\",  # 2001 unique values\n",
    "    \"Wind_Direction\": \"base_4\",  # 24 unique values (after cleaning)\n",
    "    \"Weather_Condition\": \"base_4\",  # 127 unique values\n",
    "    \"Sunrise_Sunset\": \"base_2\",  # 2 unique values\n",
    "    \"Civil_Twilight\": \"base_2\",  # 2 unique values\n",
    "    \"Nautical_Twilight\": \"base_2\",  # 2 unique value\n",
    "    \"Astronomical_Twilight\": \"base_2\",  # 2 unique value\n",
    "    #\n",
    "    # engineered features\n",
    "    \"zip_02\": \"ordinal\",\n",
    "    \"zip_25\": \"ordinal\",\n",
    "}\n",
    "```\n",
    "\n",
    "## Model training and evaluation\n",
    "\n",
    "1. Data was fitted using decison trees\n",
    "1. used only one hyperparameter for tuning : `max_depth`\n",
    "1. Evaluation was done using:\n",
    "    - Precision recall matrix (derived from confusion matrix)\n",
    "    - log_loss (metric)\n",
    "1. Model performed well on training and cross validation dataset but poorly performed on test set\n",
    "1. One major reason for this behaviour could be - distributions of class labels in train and test set:\n",
    "\n",
    "    ```plain_text\n",
    "    class label counts of test set\n",
    "    2    379695\n",
    "    3    111298\n",
    "    1     28205\n",
    "    4     19989\n",
    "    Name: Severity, dtype: int64\n",
    "\n",
    "    class label counts of train set\n",
    "    2    1993515\n",
    "    3     887615\n",
    "    4      92331\n",
    "    1        969\n",
    "    Name: Severity, dtype: int64\n",
    "    ```\n",
    "1. Class weights added during training did not work well during test set\n",
    "\n",
    "## Interpretation of results\n",
    "\n",
    "Interpretation of predictions of this manner was done using external library:\n",
    "    ```plain_text\n",
    "    Predicted class  [3]\n",
    "    Actual class  [3] \n",
    "\n",
    "    Path taken:\n",
    "\n",
    "    zip_02_0 < 46.5\n",
    "    0.5 <= kw_Northbound \n",
    "    kw_Hwy < 0.5\n",
    "    0.5 <= Airport_Code_6 \n",
    "    Airport_Code_10 < 0.5\n",
    "    City_0 < 0.5\n",
    "    City_4 < 0.5\n",
    "    Side_0 < 0.5\n",
    "    0.5 <= Source_0 \n",
    "    Distance(mi) < 1.41\n",
    "    Traffic_Signal < 0.5\n",
    "    zip_len < 7.5\n",
    "    ```\n",
    "\n",
    "Also feature importances were calculated in the end.\n",
    "\n",
    "\n",
    "## Future steps\n",
    "\n",
    "1. Use ensemble methods to model the data and see the impact on log loss\n",
    "1. Improve feature set by encoding text in a better format (text2vec)\n",
    "1. Regularly train model on latest data so that model is robust to class imbalance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
